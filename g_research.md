---
layout: page
title: Research
permalink: /research/
---


#### **JOURNALS**

<table border="0">
<tr>
		<td valign="top" width="220px">
		<img src="https://github.com/bitwangyujia/research/blob/master/images/comic20speech.png?raw=true" width="200">
		</td>
		<td valign="top" width="400">
			<tf1><b>Yujia Wang</b>, Wenguan Wang, Wei Liang, Lap-Fai Yu</tf1><br>
			<tf1><strong>Comic-Guided Speech Synthesis.</strong></tf1><br>
			<tf1>ACM Transactions on Graphics (<strong>Proceeding of SIGGRAPH Asia 2019</strong>)</tf1><br>
			<tf1><a href="https://bitwangyujia.github.io/research/project/comic2speech.html" target="_blank" rel="nofollow">Project Page</a>, <a href="https://bitwangyujia.github.io/research/paper/siga19-comic.pdf" target="_blank" rel="nofollow">Paper</a>, <a href="https://www.youtube.com/watch?v=2cOgWoejbr8&feature=youtu.be" target="_blank" rel="nofollow">Video</a>, <a href="https://bitwangyujia.github.io/research/all_bib.html#comic_speech" target="_blank" rel="nofollow">Bibtex</a></tf1><br>
		</td>						
</tr>
<tr>
		<td valign="top" width="220px">
		<img src="https://github.com/bitwangyujia/research/blob/master/images/head_pose_avatar.gif?raw=true" width="200">
		</td>
		<td valign="top" width="400">
			<tf1> <b>Yujia Wang</b>, Wei Liang, Shenjian Bing, Yunde Jia, Lap-Fai Yu</tf1><br>
			<tf1><strong>A Deep Coarse-to-Fine Network for Head Pose Estimation from Synthetic Data.</strong></tf1><br>
			<tf1> Pattern Recognition (<strong>PR</strong>), 2019</tf1><br>
			<tf1><a href="https://liangwei-bit.github.io/web/project/headpose/" target="_blank" rel="nofollow">Project Page</a>, <a href="https://bitwangyujia.github.io/research/paper/PR-headpose-2019.pdf" target="_blank" rel="nofollow">Paper</a>, <a href="http://iitlab.bit.edu.cn/mcislab/~liangwei/projects/headpose/head_pose_estimation_PR.mp4" target="_blank" rel="nofollow">Video</a>, <a href="https://bitwangyujia.github.io/research/all_bib.html#head_pose" target="_blank" rel="nofollow">Bibtex</a></tf1><br>
		</td>						
</tr>
</table>

<br>

#### **CONFERENCES**

<table border="0">
<tr>
		<td valign="top" width="220px">
		<img src="https://github.com/bitwangyujia/research/blob/master/images/dresssynthesis.png?raw=true" width="220">
		</td>
		<td valign="top" width="400">
			<tf1>Sifan Hou, <b>Yujia Wang</b>, Wei Liang, Bing Ning</tf1><br>
			<tf1><strong>Climaxing VR Character with Scene-Aware Aesthetic Dress Synthesis.</strong></tf1><br>
			<tf1>IEEE Virtual Reality (<strong>VR 2021</strong>)</tf1><br>
			<tf1><a href="https://bitwangyujia.github.io/research/project/dresssynthesis.html" target="_blank" rel="nofollow">Project Page</a>, <a href="https://bitcynthia.github.io/homepage/research/paper/VR_dress.pdf" target="_blank" rel="nofollow">Paper</a>, <a href="https://youtu.be/5fOAPo1Z4pc" target="_blank" rel="nofollow">Video</a>, <a href="https://bitwangyujia.github.io/research/all_bib.html#dress_synthesis" target="_blank" rel="nofollow">Bibtex</a></tf1><br>
		</td>						
</tr>
<tr>
		<td valign="top" width="220px">
		<img src="https://github.com/bitwangyujia/research/blob/master/images/ad.png?raw=true" width="220">
		</td>
		<td valign="top" width="400">
			<tf1><b>Yujia Wang</b>, Wei Liang, Haikun Huang, Yongqi Zhang, Dingzeyu Li, Lap-Fai Yu</tf1><br>
			<tf1><strong>Toward Automatic Audio Description Generation for Accessible Videos.</strong></tf1><br>
			<tf1>ACM Conference on Human Factors in Computing Systems (<strong>CHI 2021</strong>)</tf1><br>
			<tf1><a href="https://bitwangyujia.github.io/research/project/ad.html" target="_blank" rel="nofollow">Project Page</a>, <a href="https://bitwangyujia.github.io/research/paper/SIGCHI2021-ad.pdf" target="_blank" rel="nofollow">Paper</a>, <a href="https://youtu.be/S45vFg476aM" target="_blank" rel="nofollow">Video</a>, <a href="https://bitwangyujia.github.io/research/all_bib.html#scene_music" target="_blank" rel="nofollow">Bibtex</a></tf1><br>
		</td>						
</tr>
<tr>
		<td valign="top" width="220px">
		<img src="https://github.com/bitwangyujia/research/blob/master/images/scene2bgm.png?raw=true" width="220">
		</td>
		<td valign="top" width="400">
			<tf1><b>Yujia Wang</b>, Wei Liang, Wanwan Li, Dingzeyu Li, Lap-Fai Yu</tf1><br>
			<tf1><strong>Scene-Aware Background Music Synthesis.</strong></tf1><br>
			<tf1>ACM Multimedia Conference (<strong>MM 2020</strong>)</tf1><br>
			<p style="color:#1E90FF">Oral Presentation (9% acceptance rate)</p>
			<tf1><a href="https://bitwangyujia.github.io/research/project/scene2music.html" target="_blank" rel="nofollow">Project Page</a>, <a href="https://bitwangyujia.github.io/research/paper/MM-music.pdf" target="_blank" rel="nofollow">Paper</a>, <a href="https://youtu.be/fG2u2QG8ejU" target="_blank" rel="nofollow">Video</a>, <a href="https://bitwangyujia.github.io/research/all_bib.html#scene_music" target="_blank" rel="nofollow">Bibtex</a></tf1><br>
		</td>						
</tr>
<tr>
		<td valign="top" width="220px">
		<img src="https://github.com/bitwangyujia/research/blob/master/images/characterpose.png?raw=true" width="220">
		</td>
		<td valign="top" width="400">
			<tf1><b>Yujia Wang</b>, Sifan Hou, Bing Ning, Wei Liang</tf1><br>
			<tf1><strong>Photo Stand-Out: Photography with Virtual Character.</strong></tf1><br>
			<tf1>ACM Multimedia Conference (<strong>MM 2020</strong>)</tf1><br>
			<p style="color:#1E90FF">Oral Presentation (9% acceptance rate)</p>
			<tf1><a href="https://bitwangyujia.github.io/research/project/posesynthesis.html" target="_blank" rel="nofollow">Project Page</a>, <a href="https://bitwangyujia.github.io/research/paper/MM-pose.pdf" target="_blank" rel="nofollow">Paper</a>, <a href="https://youtu.be/0BS8AgvpWA8" target="_blank" rel="nofollow">Video</a>, <a href="https://bitwangyujia.github.io/research/all_bib.html#character_pose" target="_blank" rel="nofollow">Bibtex</a></tf1><br>
		</td>						
</tr>
<tr>
		<td valign="top" width="220px">
		<img src="https://github.com/bitwangyujia/research/blob/master/images/face-m.gif?raw=true" width="200">
		</td>
		<td valign="top" width="400">
			<tf1>Yining Lang, Wei Liang, <b>Yujia Wang</b>, Lap-Fai Yu</tf1><br>
			<tf1><strong>3D Face Synthesis Driven by Personality Impression.</strong></tf1><br>
			<tf1>AAAI Conference on Artificial Intelligence (<strong>AAAI 2019</strong>)</tf1><br>
			<tf1><a href="https://liangwei-bit.github.io/web/project/headpose/" target="_blank" rel="nofollow">Project Page</a>, <a href="https://liangwei-bit.github.io/web/project/face/aaai19-face_v8.pdf" target="_blank" rel="nofollow">Paper</a>, <a href="https://youtu.be/YHbn7A2dNi0" target="_blank" rel="nofollow">Video</a>, <a href="https://bitwangyujia.github.io/research/all_bib.html#personality_face" target="_blank" rel="nofollow">Bibtex</a></tf1><br>
		</td>						
</tr>
</table>

<br>
